{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Required Librarries to be installed"
      ],
      "metadata": {
        "id": "LI8UQTNdWM_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exqsKVqxWL9k"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit-pypi\n",
        "!pip install ace_tools\n",
        "!pip install catboost\n",
        "!pip install pandas numpy scikit-learn xgboost catboost seaborn matplotlib tensorflow rdkit\n",
        "!pip install tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "P86E94FfWeWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats import pearsonr\n",
        "from xgboost import XGBRegressor\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "import pickle\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import os\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "ai0OoreZWgo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load your dataset: CSV format"
      ],
      "metadata": {
        "id": "1iYMJAGPWjMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(your_data)"
      ],
      "metadata": {
        "id": "SN-c4e7qWpO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "id": "pUFcl6URo9Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to convert SMILES to Molecular Fingerprints and Descriptors"
      ],
      "metadata": {
        "id": "uzWO0ORiWveL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert SMILES to molecular fingerprint\n",
        "def smiles_to_fingerprint(smiles, radius=2, n_bits=2048):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
        "        return np.array(fp)\n",
        "    else:\n",
        "        return np.zeros(n_bits)\n",
        "\n",
        "# Function to calculate RDKit descriptors\n",
        "def calculate_descriptors(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        return np.array([desc[1](mol) for desc in Descriptors.descList])\n",
        "    else:\n",
        "        return np.zeros(len(Descriptors.descList))"
      ],
      "metadata": {
        "id": "jpxJnqGCW-nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert SMILES to fingerprints and descriptors"
      ],
      "metadata": {
        "id": "Yz7RZj2LXCYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Fingerprint'] = data['SMILES'].apply(smiles_to_fingerprint)\n",
        "data['Descriptors'] = data['SMILES'].apply(calculate_descriptors)"
      ],
      "metadata": {
        "id": "mO1bQN9JXKDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine fingerprints and descriptors into one feature matrix and concatenate them in x and put target values (Molecular toxicity or property) that you want to predict."
      ],
      "metadata": {
        "id": "rMcwdcleXUB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fingerprints = np.array(data['Fingerprint'].tolist())\n",
        "descriptors = np.array(data['Descriptors'].tolist())\n",
        "X = np.concatenate([fingerprints, descriptors], axis=1)\n",
        "y = data['Experimental logEC50'].values"
      ],
      "metadata": {
        "id": "UFbllTiVXjw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the shapes of fingerprints"
      ],
      "metadata": {
        "id": "4zoHHe-kXr0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fingerprints.shape"
      ],
      "metadata": {
        "id": "VIkZqrZfXvjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the shapes of descriptors"
      ],
      "metadata": {
        "id": "lxCC4PLzXxhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "descriptors.shape"
      ],
      "metadata": {
        "id": "T9GmXcAdX1Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes fingerprints and descriptors can have missing values because of the limitations of RDkit. so, first check if there is any missing values,"
      ],
      "metadata": {
        "id": "Hp-dSD-aX8k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of missing (NaN) values in X\n",
        "missing_values_count = np.isnan(X).sum()\n",
        "\n",
        "print(\"Number of missing values in X:\", missing_values_count)"
      ],
      "metadata": {
        "id": "4rVA1tE3YNEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have missing values, you can handle missing values by imputing with the mean value or other methods. Here, we implemented the mean for handling the missing values."
      ],
      "metadata": {
        "id": "Kefs4CcbYPJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values by imputing with the mean value\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)"
      ],
      "metadata": {
        "id": "tdzLIHCiYe4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the shape of the X. the columns numbers must be as same as sum of fingerprints and descriptors."
      ],
      "metadata": {
        "id": "t68H-bPOYi_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "da6Pctr8Yu9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you can keep the name of features with the following code, if you want to have an interpretability study on the most important features."
      ],
      "metadata": {
        "id": "7XzxJw8HYw57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature names\n",
        "fingerprint_features = [f'fingerprint_{i}' for i in range(fingerprints.shape[1])]\n",
        "descriptor_features = [desc[0] for desc in Descriptors.descList]\n",
        "feature_names = fingerprint_features + descriptor_features"
      ],
      "metadata": {
        "id": "Bvq-WPs3ZAiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the length of feature_names matches the number of columns in X\n",
        "assert len(feature_names) == X.shape[1], \"Length of feature_names must match number of columns in X\""
      ],
      "metadata": {
        "id": "E5t95KbDZD2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we are going to initialize feature selection process by using Random Forest and Recursive Feature Elimination (RFE)"
      ],
      "metadata": {
        "id": "PIBugGhVZPuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Random Forest Regressor\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define a range of features to evaluate\n",
        "# Since we have 2,258 features, we can start with larger steps initially and then narrow down\n",
        "feature_range = list(range(50, 1001, 50)) + list(range(1000, 2001, 200)) + [2258]\n",
        "\n",
        "scores = []\n",
        "\n",
        "# Perform RFE for each number of features in the range\n",
        "for n_features in feature_range:\n",
        "    selector = RFE(estimator=rf, n_features_to_select=n_features, step=50)\n",
        "    score = cross_val_score(selector, X, y, cv=5, scoring='r2').mean()  # Using R² as a performance metric\n",
        "    scores.append(score)"
      ],
      "metadata": {
        "id": "Ojf4erwbZjTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the optimal number of features\n",
        "optimal_features = feature_range[np.argmax(scores)]\n",
        "print(f'Optimal number of features: {optimal_features}')\n"
      ],
      "metadata": {
        "id": "HYJTdNO4ZqYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the optimal number of features, we implemented \"Elbow Method\""
      ],
      "metadata": {
        "id": "L5TNGIouZwsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the scores to find the optimal number of features\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(feature_range, scores, marker='o')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.ylabel('Cross-Validation R² Score')\n",
        "plt.title('Elbow Method for Optimal Number of Features')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Find the optimal number of features\n",
        "optimal_features = feature_range[np.argmax(scores)]\n",
        "print(f'Optimal number of features: {optimal_features}')"
      ],
      "metadata": {
        "id": "uqc1datkZ--7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refit the RFE selctor with the optimal number of features"
      ],
      "metadata": {
        "id": "q5x6z0n7aCeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selector = RFE(estimator=rf, n_features_to_select=optimal_features, step=50)\n",
        "selector = selector.fit(X, y)"
      ],
      "metadata": {
        "id": "WhoCPjczaIK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform data to select the optimal features"
      ],
      "metadata": {
        "id": "dNiJtcepaLNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_selected = selector.transform(X)\n",
        "print(f'Shape of the new feature set: {X_selected.shape}')"
      ],
      "metadata": {
        "id": "ZPNS6X3gaQ4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you want to get the ranking of the features from the RFE selector run the code below. This code gives you the most important features names."
      ],
      "metadata": {
        "id": "iWi5PIglpb1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the ranking of the features from the RFE selector\n",
        "ranking = selector.ranking_\n",
        "\n",
        "# Identify the important features (those with a ranking of 1)\n",
        "important_indices = np.where(ranking == 1)[0]\n",
        "important_features = [feature_names[i] for i in important_indices]\n",
        "\n",
        "# Get the feature importances from the RandomForest model\n",
        "importances = selector.estimator_.feature_importances_\n",
        "\n",
        "# Sort the features by importance\n",
        "sorted_indices = np.argsort(importances)[::-1]\n",
        "sorted_features = [important_features[i] for i in sorted_indices]\n",
        "sorted_importances = importances[sorted_indices]\n",
        "\n",
        "# Plot the top N important features\n",
        "N = 20  # Number of top features to display\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(sorted_features[:N], sorted_importances[:N], color='skyblue')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature Name')\n",
        "plt.title(f'Top {N} Important Features')\n",
        "plt.gca().invert_yaxis()  # To have the most important feature at the top\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8JCDAdsSpq6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into training and testing sets and check the shapes of each set."
      ],
      "metadata": {
        "id": "3VpBTcmhaYjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "vZuxnKwiadk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "wl6TKDrOakVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "IQCuIgThak5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training base models (RF: random forest, SVR: support vector machine, catboost, Chemception)"
      ],
      "metadata": {
        "id": "r44wPKiBamri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are going to use GridsearchCV for finding the best hyperparameters."
      ],
      "metadata": {
        "id": "ANemLPY1a2zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter grids for base models\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "param_grid_svr = {\n",
        "    'kernel': ['rbf'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "param_grid_catboost = {\n",
        "    'depth': [6, 8],\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "    'iterations': [100, 200]\n",
        "}\n"
      ],
      "metadata": {
        "id": "y9GX2oaRa1al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearch for hyperparameter tuning\n",
        "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search_svr = GridSearchCV(SVR(), param_grid_svr, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search_catboost = GridSearchCV(CatBoostRegressor(random_state=42, silent=True), param_grid_catboost, cv=5, n_jobs=-1, verbose=1)\n",
        "\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "grid_search_svr.fit(X_train, y_train)\n",
        "grid_search_catboost.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_search_rf.best_estimator_\n",
        "best_svr = grid_search_svr.best_estimator_\n",
        "best_catboost = grid_search_catboost.best_estimator_"
      ],
      "metadata": {
        "id": "D1_unpyzbCme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "defining the Chemception model"
      ],
      "metadata": {
        "id": "jK1xPWi6bIJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemception model definition\n",
        "def create_chemception_model(input_shape, filters=32, kernel_size=3, pool_size=2, dense_units=100, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "Qm_TcaJubK-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap Chemception model for hyperparameter tuning\n",
        "chemception = KerasRegressor(build_fn=create_chemception_model, input_shape=(X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "sWuH8kbhbOnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter grid for Chemception\n",
        "param_distribs_chemception = {\n",
        "    'filters': [32, 64],\n",
        "    'kernel_size': [3, 5],\n",
        "    'pool_size': [2, 3],\n",
        "    'dense_units': [50, 100],\n",
        "    'epochs': [10, 20],\n",
        "    'batch_size': [10, 20],\n",
        "    'learning_rate': [0.001, 0.01]\n",
        "}"
      ],
      "metadata": {
        "id": "hZ4vAHc7bQfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV for Chemception\n",
        "random_search_chemception = RandomizedSearchCV(chemception, param_distribs_chemception, n_iter=10, cv=3, n_jobs=-1, verbose=1)\n",
        "random_search_chemception.fit(X_train.reshape(-1, X_train.shape[1], 1), y_train)\n",
        "\n",
        "best_chemception = random_search_chemception.best_estimator_"
      ],
      "metadata": {
        "id": "-ikP_85hbS_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to see the total parameters for best_chemception mode, you can use this code."
      ],
      "metadata": {
        "id": "tVhETQ3DbXw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_chemception.model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LJ68gqwfbgJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are going to generate cross-validated predictions for each base model and create meta-features."
      ],
      "metadata": {
        "id": "W4GPBheBbmBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_features = np.zeros((X_train.shape[0], 4))\n",
        "meta_features[:, 0] = cross_val_predict(best_rf, X_train, y_train, cv=5)\n",
        "meta_features[:, 1] = cross_val_predict(best_svr, X_train, y_train, cv=5)\n",
        "meta_features[:, 2] = cross_val_predict(best_catboost, X_train, y_train, cv=5)"
      ],
      "metadata": {
        "id": "LpfqaYFybvYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure predictions are reshaped correctly\n",
        "chemception_predictions = cross_val_predict(best_chemception, X_train.reshape(-1, X_train.shape[1], 1), y_train, cv=5)\n",
        "meta_features[:, 3] = chemception_predictions.reshape(-1)"
      ],
      "metadata": {
        "id": "WaYfLpIBbyN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now, after having meta-feature, we are going to initialize the meta-model which is XGBoost in this study."
      ],
      "metadata": {
        "id": "PiG06P_MbzvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter grid for meta-model (XGBoost)\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.01, 0.1, 0.02],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# GridSearchCV for meta-model\n",
        "grid_search_xgb = GridSearchCV(XGBRegressor(random_state=42), param_grid_xgb, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search_xgb.fit(meta_features, y_train)\n",
        "\n",
        "best_xgb = grid_search_xgb.best_estimator_"
      ],
      "metadata": {
        "id": "XZu3kOMdb89K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "then, you have to generate the same features for test dataset."
      ],
      "metadata": {
        "id": "tspL8Ej5cFh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_meta_features = np.zeros((X_test.shape[0], 4))\n",
        "test_meta_features[:, 0] = best_rf.predict(X_test)\n",
        "test_meta_features[:, 1] = best_svr.predict(X_test)\n",
        "test_meta_features[:, 2] = best_catboost.predict(X_test)\n",
        "# Ensure predictions are reshaped correctly\n",
        "chemception_test_predictions = best_chemception.predict(X_test.reshape(-1, X_test.shape[1], 1))\n",
        "test_meta_features[:, 3] = chemception_test_predictions.reshape(-1)"
      ],
      "metadata": {
        "id": "eZbCbt7XcMb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we are going to do the final prediction by using meta-model which has been trained based on the best hyperparameters which GridsearchCV found."
      ],
      "metadata": {
        "id": "KU5sk9O5cSZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make final predictions\n",
        "final_predictions = best_xgb.predict(test_meta_features)"
      ],
      "metadata": {
        "id": "ik-WHgmqcfue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the performance with difference metrics."
      ],
      "metadata": {
        "id": "d5iZiLQKciiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, final_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, final_predictions)\n",
        "r2 = r2_score(y_test, final_predictions)\n",
        "pearson_corr, _ = pearsonr(y_test, final_predictions)\n",
        "\n",
        "# Print the metrics\n",
        "metrics = {\n",
        "    'RMSE': rmse,\n",
        "    'MAE': mae,\n",
        "    'R-squared': r2,\n",
        "    'Pearson Correlation': pearson_corr\n",
        "}\n",
        "\n",
        "# Display the metrics\n",
        "metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
        "print(metrics_df)"
      ],
      "metadata": {
        "id": "qus44jtXcmFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot for predicted vs actual values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, final_predictions, alpha=0.6, color='b')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
        "plt.xlabel('Actual Experimental logEC50')\n",
        "plt.ylabel('Predicted Experimental logEC50')\n",
        "plt.title('Actual vs Predicted Experimental logEC50')\n",
        "plt.show()\n",
        "\n",
        "# Residuals plot\n",
        "residuals = y_test - final_predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(residuals, kde=True, color='r')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Residuals Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CJ8oPiySctKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate the Standard Deviatin of Errors."
      ],
      "metadata": {
        "id": "7ECs62uPcvmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errors = y_test - final_predictions\n",
        "std_dev = np.std(errors)\n",
        "print(f'Standard Deviation of Errors: {std_dev}')"
      ],
      "metadata": {
        "id": "Tcw2L5-_c0PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the mean and standard error and  Calculate the 95% confidence interval"
      ],
      "metadata": {
        "id": "WJLiE5p9c3uR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean and standard error\n",
        "mean_pred = np.mean(final_predictions)\n",
        "std_dev = np.std(final_predictions, ddof=1)  # Use ddof=1 for sample standard deviation\n",
        "n = len(final_predictions)\n",
        "std_err = std_dev / np.sqrt(n)\n",
        "\n",
        "# Calculate the 95% confidence interval\n",
        "confidence_level = 0.95\n",
        "degrees_freedom = n - 1\n",
        "confidence_interval = stats.t.interval(confidence_level, degrees_freedom, mean_pred, std_err)\n",
        "\n",
        "\n",
        "print(f\"Mean prediction: {mean_pred:.4f}\")\n",
        "print(f\"95% Confidence Interval: {confidence_interval}\")"
      ],
      "metadata": {
        "id": "86GCGtG6c945"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, you can calculate standard deviation and mean for the predictions and the 95% confidence interval for each point and confidence intervals for each point."
      ],
      "metadata": {
        "id": "B0DLfL3_dBZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate standard deviation and mean for the predictions\n",
        "mean_pred = np.mean(final_predictions)\n",
        "std_dev = np.std(final_predictions, ddof=1)\n",
        "\n",
        "# Calculate the 95% confidence interval for each point\n",
        "n = len(final_predictions)\n",
        "confidence_interval = stats.t.interval(0.95, n-1, loc=mean_pred, scale=std_dev/np.sqrt(n))\n",
        "\n",
        "# Calculate confidence intervals for each point\n",
        "confidence_intervals = []\n",
        "for pred in final_predictions:\n",
        "    ci_low = pred - 1.96 * (std_dev / np.sqrt(n))\n",
        "    ci_high = pred + 1.96 * (std_dev / np.sqrt(n))\n",
        "    confidence_intervals.append((ci_low, ci_high))\n",
        "\n",
        "# Print the first few confidence intervals\n",
        "print(confidence_intervals[:5])"
      ],
      "metadata": {
        "id": "x4-SQGjrdGsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate t_test and P-value"
      ],
      "metadata": {
        "id": "5_SrKDSvdKiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Perform a paired t-test\n",
        "t_stat, p_value = ttest_rel(final_predictions, y_test)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "gVrpiZNvdQAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print values to inspect"
      ],
      "metadata": {
        "id": "tcYyujuxdT3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted values:\", final_predictions)\n",
        "print(\"Actual values:\", y_test)"
      ],
      "metadata": {
        "id": "EtWoQBc0dV3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "differences = np.abs(final_predictions - y_test)\n",
        "print(\"Absolute differences:\", differences)"
      ],
      "metadata": {
        "id": "KNWQS7evdYWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate absolute differences and plot them to analyze visually"
      ],
      "metadata": {
        "id": "blNocRqxdaVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate absolute differences\n",
        "differences = np.abs(final_predictions - y_test)\n",
        "print(\"Absolute differences:\", differences)\n",
        "\n",
        "# Plot the differences\n",
        "plt.figure(figsize=(10, 6))\n",
        "x = np.arange(1, len(differences) + 1)\n",
        "plt.plot(x, differences, 'o-', label='Absolute Difference')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Data Point')\n",
        "plt.ylabel('Absolute Difference')\n",
        "plt.title('Absolute Differences Between Predicted and Actual Values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hN_lCqPwdbDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate synthetic p-values for demonstration"
      ],
      "metadata": {
        "id": "COhAoPyLdj8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic p-values for demonstration\n",
        "np.random.seed(42)\n",
        "p_values = np.random.uniform(0, 0.1, len(final_predictions))  # Simulating some p-values for illustration\n",
        "\n",
        "# Set up the plot\n",
        "x = np.arange(1, len(p_values) + 1)\n",
        "significance_level = 0.05\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the p-values\n",
        "plt.plot(x, p_values, 'o-', label='p-value')\n",
        "\n",
        "# Add shading for significant p-values (p < 0.05)\n",
        "plt.fill_between(x, 0, significance_level, where=p_values < significance_level, color='red', alpha=0.3, label='Significant (p < 0.05)')\n",
        "\n",
        "# Add a horizontal line at the significance level\n",
        "plt.axhline(y=significance_level, color='gray', linestyle='--', label='Significance level (0.05)')\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel('Data Point')\n",
        "plt.ylabel('p-value')\n",
        "plt.title('P-values with Shaded Significance Area')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nzj19KxLdq4Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}